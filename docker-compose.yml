networks:
  llama-net:
    driver: bridge

services:
  ollama:
    build: .
    container_name: ollama
    user: root
    ports:
      - "11434:11434"
    networks:
      - llama-net
    tty: true

  backend:
    build: ./back-end
    container_name: backend
    ports:
      - "8000:8000"
    depends_on:
      - ollama
    restart: on-failure
    env_file:
      - .env
    networks:
      - llama-net

  frontend:
    build: ./front-end
    container_name: frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - llama-net
